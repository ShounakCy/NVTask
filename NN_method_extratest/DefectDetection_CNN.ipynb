{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Activation\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers. Params. Preprocesing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(generator):\n",
    "    for batch in generator:\n",
    "        yield (batch, batch)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test any image\n",
    "def ImageHasdefect(model, filePath,threshold):  \n",
    "    im = cv2.resize(cv2.imread(filePath), (3660, 252))\n",
    "    im = im * 1./255\n",
    "\n",
    "    #validation_image = np.zeros((1,  3660, 252, 3))\n",
    "    validation_image[0, :, :, :] = im;   \n",
    "    predicted_image = model.predict(validation_image)\n",
    "    _mse = mse(predicted_image[0], validation_image[0]) \n",
    "    print('_mse: {}'.format(_mse))\n",
    "    return _mse  > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 252, 3660\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "nb_validation_samples=0\n",
    "nb_train_samples=0\n",
    "\n",
    "nb_epoch=20\n",
    "\n",
    "initial_image_dir='.NN_method/images/docs'\n",
    "train_data_dir = initial_image_dir + '/train'\n",
    "validation_data_dir = initial_image_dir + '/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator for images to complete dataset\n",
    "Generator is used for extending the image dataset by image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=2,\n",
    "         \n",
    "        rescale=1./255,\n",
    "        \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New image generation flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate additional images for train in: /efs/workspace/cnn-anomaly-detection-keras/images/docs/train/correct_samples\n",
      "generate additional images for validation in: /efs/workspace/cnn-anomaly-detection-keras/images/docs/valid/correct_samples\n",
      "generate additional images for train in: /efs/workspace/cnn-anomaly-detection-keras/images/docs/train/correct_samples\n",
      "generate additional images for validation in: /efs/workspace/cnn-anomaly-detection-keras/images/docs/valid/correct_samples\n",
      "generate additional images for train in: /efs/workspace/cnn-anomaly-detection-keras/images/docs/train/correct_samples\n",
      "generate additional images for validation in: /efs/workspace/cnn-anomaly-detection-keras/images/docs/valid/correct_samples\n",
      "-------------------------------------------\n",
      "Initial image count: 3 \n",
      "Train image count: 299 \n",
      "Validation image count: 63 \n"
     ]
    }
   ],
   "source": [
    "image_list = os.listdir(initial_image_dir) #initial path to images\n",
    "\n",
    "inital_image_count=0\n",
    "for img in image_list:   \n",
    "    img_path= initial_image_dir + '/' + img\n",
    "    if not os.path.isfile(img_path):\n",
    "        continue\n",
    "       \n",
    "    inital_image_count += 1  \n",
    "    \n",
    "    img = load_img(img_path)  # this is a PIL image\n",
    "    x = img_to_array(img)  \n",
    "    x = x.reshape((1,) + x.shape)  \n",
    "    \n",
    "    train_save_to = train_data_dir + '/correct_samples'\n",
    "    if not os.path.exists(train_save_to):\n",
    "        os.makedirs(train_save_to)\n",
    "    \n",
    "    valid_save_to = validation_data_dir + '/correct_samples'\n",
    "    if not os.path.exists(valid_save_to):\n",
    "        os.makedirs(valid_save_to)\n",
    "    \n",
    "    print(\"generate additional images for train in: \" + train_save_to)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=5, save_to_dir = train_save_to, save_prefix='sampleIM', save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 100:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "    train_size=0            \n",
    "    for t in os.listdir(train_save_to):\n",
    "        if os.path.isfile(train_save_to +\"/\" + t):\n",
    "            train_size += 1 \n",
    "            \n",
    "            \n",
    "    print(\"generate additional images for validation in: \" + valid_save_to)\n",
    "    j=0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir=valid_save_to, save_prefix='valIm', save_format='jpg'):\n",
    "        j += 1\n",
    "        if j > 20:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "            \n",
    "    validation_size=0            \n",
    "    for v in os.listdir(valid_save_to):\n",
    "        if os.path.isfile(valid_save_to+\"/\" +v):\n",
    "            validation_size += 1 \n",
    "            \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Initial image count: {} \".format(inital_image_count))\n",
    "print(\"Train image count: {} \".format(train_size))\n",
    "print(\"Validation image count: {} \".format(validation_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exract data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 299 images belonging to 1 classes.\n",
      "Found 63 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "# only rescaling\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  \n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb', \n",
    "        class_mode=None)  \n",
    "\n",
    "nb_train_samples=train_generator.samples\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb', \n",
    "        class_mode=None)\n",
    "\n",
    "nb_validation_samples=validation_generator.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Simplest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 252, 3660, 3)]    0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 252, 3660, 16)     448       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 126, 1830, 16)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 126, 1830, 8)      1160      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 63, 915, 8)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 63, 915, 8)        584       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 458, 8)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 458, 8)        584       \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 64, 916, 8)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 64, 916, 8)        584       \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 128, 1832, 8)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 126, 1830, 16)     1168      \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 252, 3660, 16)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 252, 3660, 3)      435       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,963\n",
      "Trainable params: 4,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(batch_shape=(None, img_width, img_height, 3))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "model = Model(input_img, decoded)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.6819 - val_loss: 0.6554\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.6234 - val_loss: 0.6074\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.5885 - val_loss: 0.5662\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.5448 - val_loss: 0.5207\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.4901 - val_loss: 0.4670\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.4668 - val_loss: 0.4655\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.4607 - val_loss: 0.4550\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.4607 - val_loss: 0.4667\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.4591 - val_loss: 0.4579\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.4588 - val_loss: 0.4609\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 41s 5s/step - loss: 0.4580 - val_loss: 0.4602\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.4600 - val_loss: 0.4633\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 41s 5s/step - loss: 0.4577 - val_loss: 0.4564\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 39s 5s/step - loss: 0.4583 - val_loss: 0.4574\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.4587 - val_loss: 0.4594\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.4571 - val_loss: 0.4525\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 41s 5s/step - loss: 0.4591 - val_loss: 0.4589\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 40s 5s/step - loss: 0.4568 - val_loss: 0.4576\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 41s 5s/step - loss: 0.4574 - val_loss: 0.4518\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 39s 5s/step - loss: 0.4574 - val_loss: 0.4605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad86cb8d90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        fixed_generator(train_generator),\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=fixed_generator(validation_generator),\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('defect-detection.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('defect-detection.h5');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test encoder and visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = next(validation_generator)[:7] # Get random image\n",
    "\n",
    "dec = model.predict(img) # Decoded image\n",
    "img = img[0]\n",
    "dec = dec[0]\n",
    "img = (img*255).astype('uint8')\n",
    "dec = (dec*255).astype('uint8')\n",
    "\n",
    "plt.imshow(np.hstack((img, dec)))\n",
    "plt.title('Original and reconstructed images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Selecting th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base on visulization lets say that everething that more then threshold likelihood defect\n",
    "# set threshold manually\n",
    "threshold=0.00065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 807ms/step\n",
      "_mse: 0.0006001763445255377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking against correct images as the model is trained with defective images\n",
    "ImageHasdefect(model, './NN_method/correct.jpg',threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('PIPrediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd299929b67f6cd9745e09101b4b10e49988cd51c7664d2dab32a2fed4aee934"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
